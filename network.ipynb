{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "virgin-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "south-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel (r'data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sustained-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Fallnummer'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "everyday-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientClassificationNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, activation=torch.relu):\n",
    "        super(PatientClassificationNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.activation = activation\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "skilled-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,['AGE','Admission type 2','No. of times sent to ICU','FA ab para']]\n",
    "X['FA ab para'] = X['FA ab para'].replace([1,5, 10, 14, 16, 21, 22], X['FA ab para'].max()+1)\n",
    "X = torch.Tensor(X.to_numpy())\n",
    "fa_val = X[:, 3].unique()\n",
    "tmp = X[:,3].unsqueeze(1).expand((-1,len(fa_val))) == fa_val\n",
    "X = torch.cat((X[:, :3], tmp.float()), dim=1)\n",
    "X[:,2] = (X[:,2] > 1 )\n",
    "X = (X - X.mean(0)) / X.std(0)\n",
    "\n",
    "Y = df.loc[:,['Tod']]\n",
    "Y = torch.Tensor(Y.to_numpy())\n",
    "\n",
    "num_feature = X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "vital-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(X) * 0.8)\n",
    "shuffle_indices = np.arange(len(X))\n",
    "np.random.shuffle(shuffle_indices)\n",
    "X = X[shuffle_indices]\n",
    "Y = Y[shuffle_indices]\n",
    "X_train = X[:num_train]\n",
    "y_train = Y[:num_train]\n",
    "X_test = X[num_train:]\n",
    "y_test = Y[num_train:]\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_test = TensorDataset(X_test, y_test)\n",
    "trainloader = DataLoader(dataset_train, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(dataset_test, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "commercial-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PatientClassificationNet(num_feature,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "heated-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = y_train.nonzero().size(0)/num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "emotional-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, testloader, epoch=5):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(epoch):\n",
    "        total_loss = 0\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "#             print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss\n",
    "        \n",
    "        net.eval()\n",
    "        correct_true = 0\n",
    "        predicted_true = 0\n",
    "        target_true = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(testloader):\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            prediction = outputs > threshold\n",
    "            correct_true += ((prediction==1) * (labels==1)).sum().item()\n",
    "            target_true += labels.sum().item()\n",
    "            predicted_true += prediction.sum().item()\n",
    "            total += labels.size(0)\n",
    "        recall = correct_true / target_true\n",
    "        precision = correct_true / predicted_true\n",
    "        f1_score = 2 * precision * recall / (precision + recall)\n",
    "        print(f'epoch {epoch}: recall: {recall} precision: {precision} f1_score: {f1_score} loss:{total_loss}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "expanded-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: recall: 0.2692307692307692 precision: 0.0532994923857868 f1_score: 0.08898305084745763 loss:13.706671714782715\n",
      "epoch 1: recall: 0.8076923076923077 precision: 0.07046979865771812 f1_score: 0.12962962962962962 loss:9.786781311035156\n",
      "epoch 2: recall: 0.7564102564102564 precision: 0.0978441127694859 f1_score: 0.17327459618208516 loss:9.009078979492188\n",
      "epoch 3: recall: 0.7948717948717948 precision: 0.12757201646090535 f1_score: 0.2198581560283688 loss:8.69239616394043\n",
      "epoch 4: recall: 0.7564102564102564 precision: 0.13470319634703196 f1_score: 0.22868217054263565 loss:8.505622863769531\n",
      "epoch 5: recall: 0.7307692307692307 precision: 0.14578005115089515 f1_score: 0.24307036247334754 loss:8.37975788116455\n",
      "epoch 6: recall: 0.7692307692307693 precision: 0.1366742596810934 f1_score: 0.23210831721470018 loss:8.198456764221191\n",
      "epoch 7: recall: 0.7307692307692307 precision: 0.1503957783641161 f1_score: 0.24945295404814005 loss:8.32370376586914\n",
      "epoch 8: recall: 0.7307692307692307 precision: 0.15240641711229946 f1_score: 0.2522123893805309 loss:8.079743385314941\n",
      "epoch 9: recall: 0.7692307692307693 precision: 0.13729977116704806 f1_score: 0.23300970873786406 loss:8.163886070251465\n",
      "epoch 10: recall: 0.7435897435897436 precision: 0.14795918367346939 f1_score: 0.24680851063829787 loss:8.05609130859375\n",
      "epoch 11: recall: 0.7435897435897436 precision: 0.14180929095354522 f1_score: 0.2381930184804928 loss:8.094219207763672\n",
      "epoch 12: recall: 0.7435897435897436 precision: 0.14871794871794872 f1_score: 0.24786324786324784 loss:8.068342208862305\n",
      "epoch 13: recall: 0.7564102564102564 precision: 0.14285714285714285 f1_score: 0.24032586558044808 loss:7.952118396759033\n",
      "epoch 14: recall: 0.7435897435897436 precision: 0.1518324607329843 f1_score: 0.25217391304347825 loss:8.19798755645752\n",
      "epoch 15: recall: 0.7564102564102564 precision: 0.1368909512761021 f1_score: 0.23182711198428294 loss:8.08953857421875\n",
      "epoch 16: recall: 0.7307692307692307 precision: 0.15240641711229946 f1_score: 0.2522123893805309 loss:8.160911560058594\n",
      "epoch 17: recall: 0.7564102564102564 precision: 0.14182692307692307 f1_score: 0.23886639676113358 loss:8.004129409790039\n",
      "epoch 18: recall: 0.7564102564102564 precision: 0.13140311804008908 f1_score: 0.2239089184060721 loss:7.989554405212402\n",
      "epoch 19: recall: 0.7564102564102564 precision: 0.1435523114355231 f1_score: 0.2413087934560327 loss:8.056350708007812\n",
      "epoch 20: recall: 0.7564102564102564 precision: 0.14936708860759493 f1_score: 0.24947145877378432 loss:7.995305061340332\n",
      "epoch 21: recall: 0.7435897435897436 precision: 0.15104166666666666 f1_score: 0.2510822510822511 loss:8.078035354614258\n",
      "epoch 22: recall: 0.7435897435897436 precision: 0.1407766990291262 f1_score: 0.23673469387755103 loss:7.931930065155029\n",
      "epoch 23: recall: 0.7435897435897436 precision: 0.15223097112860892 f1_score: 0.25272331154684097 loss:8.101895332336426\n",
      "epoch 24: recall: 0.7564102564102564 precision: 0.14285714285714285 f1_score: 0.24032586558044808 loss:8.124227523803711\n",
      "epoch 25: recall: 0.7435897435897436 precision: 0.13744075829383887 f1_score: 0.232 loss:8.03592300415039\n",
      "epoch 26: recall: 0.7435897435897436 precision: 0.1411192214111922 f1_score: 0.23721881390593047 loss:8.067559242248535\n",
      "epoch 27: recall: 0.782051282051282 precision: 0.1328976034858388 f1_score: 0.2271880819366853 loss:7.917755126953125\n",
      "epoch 28: recall: 0.717948717948718 precision: 0.15342465753424658 f1_score: 0.2528216704288939 loss:8.175594329833984\n",
      "epoch 29: recall: 0.7307692307692307 precision: 0.14074074074074075 f1_score: 0.23602484472049692 loss:8.075817108154297\n",
      "epoch 30: recall: 0.7435897435897436 precision: 0.1351981351981352 f1_score: 0.2287968441814596 loss:7.984232425689697\n",
      "epoch 31: recall: 0.7435897435897436 precision: 0.1411192214111922 f1_score: 0.23721881390593047 loss:8.046211242675781\n",
      "epoch 32: recall: 0.7435897435897436 precision: 0.1475826972010178 f1_score: 0.2462845010615711 loss:7.924098014831543\n",
      "epoch 33: recall: 0.7307692307692307 precision: 0.15119363395225463 f1_score: 0.25054945054945055 loss:7.934126377105713\n",
      "epoch 34: recall: 0.7564102564102564 precision: 0.14390243902439023 f1_score: 0.24180327868852455 loss:7.974672794342041\n",
      "epoch 35: recall: 0.7564102564102564 precision: 0.14114832535885166 f1_score: 0.2379032258064516 loss:8.052380561828613\n",
      "epoch 36: recall: 0.7435897435897436 precision: 0.14720812182741116 f1_score: 0.2457627118644068 loss:8.04117202758789\n",
      "epoch 37: recall: 0.7435897435897436 precision: 0.14320987654320988 f1_score: 0.2401656314699793 loss:8.061267852783203\n",
      "epoch 38: recall: 0.717948717948718 precision: 0.15217391304347827 f1_score: 0.25112107623318386 loss:7.898534774780273\n",
      "epoch 39: recall: 0.7435897435897436 precision: 0.13875598086124402 f1_score: 0.2338709677419355 loss:7.927134990692139\n",
      "epoch 40: recall: 0.7307692307692307 precision: 0.1484375 f1_score: 0.24675324675324675 loss:7.88932466506958\n",
      "epoch 41: recall: 0.7307692307692307 precision: 0.14805194805194805 f1_score: 0.2462203023758099 loss:7.860099792480469\n",
      "epoch 42: recall: 0.7564102564102564 precision: 0.1368909512761021 f1_score: 0.23182711198428294 loss:8.068881034851074\n",
      "epoch 43: recall: 0.7435897435897436 precision: 0.14987080103359174 f1_score: 0.24946236559139784 loss:7.968771457672119\n",
      "epoch 44: recall: 0.7564102564102564 precision: 0.1388235294117647 f1_score: 0.2345924453280318 loss:7.90595006942749\n",
      "epoch 45: recall: 0.7435897435897436 precision: 0.13875598086124402 f1_score: 0.2338709677419355 loss:8.06863784790039\n",
      "epoch 46: recall: 0.7435897435897436 precision: 0.1336405529953917 f1_score: 0.2265625 loss:7.99265718460083\n",
      "epoch 47: recall: 0.7307692307692307 precision: 0.14321608040201006 f1_score: 0.23949579831932774 loss:7.9120025634765625\n",
      "epoch 48: recall: 0.7435897435897436 precision: 0.1377672209026128 f1_score: 0.23246492985971942 loss:7.916130542755127\n",
      "epoch 49: recall: 0.7435897435897436 precision: 0.1358313817330211 f1_score: 0.2297029702970297 loss:8.083390235900879\n"
     ]
    }
   ],
   "source": [
    "train(net, trainloader, testloader, epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "selective-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_true = 0\n",
    "predicted_true = 0\n",
    "target_true = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    prediction = outputs > threshold\n",
    "    correct_true += ((prediction==1) * (labels==1)).sum().item()\n",
    "    target_true += labels.sum().item()\n",
    "    predicted_true += prediction.sum().item()\n",
    "    total += labels.size(0)\n",
    "recall = correct_true / target_true\n",
    "precision = correct_true / predicted_true\n",
    "f1_score = 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "australian-lodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7435897435897436 0.1358313817330211 0.2297029702970297\n"
     ]
    }
   ],
   "source": [
    "print(recall, precision, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "institutional-rubber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 78.0 427\n"
     ]
    }
   ],
   "source": [
    "print(correct_true, target_true, predicted_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "statistical-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(X_train)\n",
    "v, _ = outputs.sort(0)\n",
    "num_class = 5\n",
    "class_boundary = torch.Tensor([v[int(num_train/5*i-1)] for i in range(1,num_class+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "joint-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(X_train[0:2])\n",
    "comp = out < class_boundary\n",
    "# comp.nonzero()[0].item()\n",
    "comp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "eleven-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientGroupNet(nn.Module):\n",
    "    def __init__(self, patient_class_net, class_boundary):\n",
    "        super(PatientGroupNet, self).__init__()\n",
    "        self.patient_class_net = patient_class_net\n",
    "        self.patient_class_net.eval()\n",
    "        self.class_boundary = class_boundary\n",
    "        self.num_class = self.class_boundary.size(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patient_class_net(x)\n",
    "        comp = x < self.class_boundary\n",
    "        return self.num_class - comp.sum(-1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "prospective-queens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(843), tensor(838), tensor(869), tensor(851), tensor(853)]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = PatientGroupNet(net, class_boundary)\n",
    "out = net2(X_train)\n",
    "[torch.sum(out == i) for i in range(1, num_class+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "traditional-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(198), tensor(232), tensor(207), tensor(194), tensor(233)]"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = PatientGroupNet(net, class_boundary)\n",
    "out = net2(X_test)\n",
    "[torch.sum(out == i) for i in range(1, num_class+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "progressive-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "about-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2650, -0.8964, -0.3025,  ..., -0.5173, -0.1925, -0.0974],\n",
       "        [ 0.9705, -0.8964, -0.3025,  ..., -0.5173, -0.1925, -0.0974],\n",
       "        [ 1.1721, -0.8964, -0.3025,  ..., -0.5173, -0.1925, -0.0974],\n",
       "        ...,\n",
       "        [ 0.0130, -0.8964, -0.3025,  ..., -0.5173, -0.1925, -0.0974],\n",
       "        [-0.5917, -0.8964, -0.3025,  ..., -0.5173, -0.1925, -0.0974],\n",
       "        [ 0.5170, -0.8964,  3.3051,  ..., -0.5173, -0.1925, -0.0974]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
